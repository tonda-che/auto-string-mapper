{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6e0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from asm import AutoStringMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e01a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"column1\": [\"BMW\", \"MERCEDES\", \"VW\", \"OPEL\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294223c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMW': 'Bayrische Motorenwerke',\n",
       " 'MERCEDES': 'MERCEDES Benz Gmbh',\n",
       " 'VW': 'Volkswagen',\n",
       " 'OPEL': 'OPER'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoStringMapper(df1[\"column1\"], [\n",
    "            \"MERCEDES Benz Gmbh\",\n",
    "            \"Volkswagen\",\n",
    "            \"Opel RÃ¼sselsheim\",\n",
    "            \"Bayrische Motorenwerke\",\n",
    "            \"OPER\",\n",
    "        ]).get_mapping(similarity_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b6d08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asm.AutoStringMapper"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoStringMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class AutoStringMapper:\n",
    "    def __init__(self, from_column, to_column, ignore_case: bool = True) -> None:\n",
    "\n",
    "        from_column = self.clean_column(from_column, \"from_column\")\n",
    "        to_column = self.clean_column(to_column, \"to_column\")\n",
    "\n",
    "        unique_from_column = from_column.drop_duplicates().reset_index(drop=True)\n",
    "        unique_to_column = to_column.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        len_from_column = unique_from_column.shape[0]\n",
    "        len_to_column = unique_to_column.shape[0]\n",
    "\n",
    "        maxlen_from_column = unique_from_column.str.len().max()\n",
    "        maxlen_to_column = unique_to_column.str.len().max()\n",
    "\n",
    "        (\n",
    "            from_column_combinations,\n",
    "            to_column_combinations,\n",
    "        ) = self.create_combinations(unique_from_column, unique_to_column)\n",
    "\n",
    "        if ignore_case:\n",
    "            from_column_combinations = from_column_combinations.str.lower()\n",
    "            to_column_combinations = to_column_combinations.str.lower()\n",
    "\n",
    "        levenshtein_array = self.create_levenshtein_array(\n",
    "            from_column_combinations,\n",
    "            to_column_combinations,\n",
    "            len_from_column,\n",
    "            len_to_column,\n",
    "            maxlen_from_column,\n",
    "            maxlen_to_column,\n",
    "        )\n",
    "\n",
    "        self.distance_matrix = pd.DataFrame(\n",
    "            levenshtein_array[:, maxlen_from_column - 1, maxlen_to_column - 1].reshape(\n",
    "                [len_to_column, len_from_column]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        maxlen_matrix = self.create_maxlen_matrix(unique_from_column, unique_to_column)\n",
    "\n",
    "        self.similarity_matrix = 1 - (self.distance_matrix / maxlen_matrix)\n",
    "\n",
    "        self.similarity_matrix.index = unique_to_column.to_list()\n",
    "        self.similarity_matrix.columns = unique_from_column.to_list()\n",
    "\n",
    "    def get_mapping(self, similarity_threshold: float = 0.0) -> dict:\n",
    "        \"\"\"\n",
    "        Function to retrieve a mapping using the similarity matrix\n",
    "\n",
    "        Args:\n",
    "            similarity_threshold (float): threshold which decides how\n",
    "                similar two strings need to be in order to be included\n",
    "                into the mapping and not as np.nan\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary with the mapping from the \"from\" to the \"to\" column\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if similarity_threshold is not between 0 and 1\n",
    "\n",
    "        \"\"\"\n",
    "        if similarity_threshold < 0.0 or similarity_threshold > 1.0:\n",
    "            raise ValueError(\"Parameter similarity_threshold must be between 0 and 1\")\n",
    "\n",
    "        mapping = pd.DataFrame(self.similarity_matrix.idxmax(axis=0))\n",
    "\n",
    "        similarity_threshold_mask = (\n",
    "            self.similarity_matrix.max(axis=0) >= similarity_threshold\n",
    "        )\n",
    "\n",
    "        mapping[0] = mapping[0].where(similarity_threshold_mask, np.nan)\n",
    "\n",
    "        return mapping.to_dict()[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_column(column, column_name: str) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Cleans either of the from / to columns to be a pandas Series of type str\n",
    "\n",
    "        Args:\n",
    "            column (list, pandas.Series, np.ndarray): column to be cleaned\n",
    "            column_name (str): specifying whether this is the from or the to column\n",
    "\n",
    "        Returns:\n",
    "            pandas.Series: converted to type str\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if not of any of the expected types\n",
    "\n",
    "        \"\"\"\n",
    "        if type(column) == np.ndarray:\n",
    "            column = pd.Series(column)\n",
    "        elif type(column) == list:\n",
    "            column = pd.Series(column)\n",
    "        elif type(column) == pd.Series:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"{column_name} not of type numpy.ndarray, pandas.Series or list\"\n",
    "            )\n",
    "        return column.astype(str)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_combinations(from_column: pd.Series, to_column: pd.Series):\n",
    "        \"\"\"\n",
    "        Creates all combinations of strings in the from column with all strings\n",
    "        in the to column returning it as two pandas.Series to be interpreted\n",
    "        together\n",
    "\n",
    "        Args:\n",
    "            from_column (pandas.Series): column that is mapped from\n",
    "            to_column (pandas.Series): column that is mapped to\n",
    "\n",
    "        Returns:\n",
    "            tuple: tuple including all the combinations with the from_column strings\n",
    "                as the first entry and the to_column strings as the second\n",
    "        \"\"\"\n",
    "\n",
    "        len_to_column = to_column.shape[0]\n",
    "        len_from_column = from_column.shape[0]\n",
    "\n",
    "        from_column_combinations = pd.Series(from_column.tolist() * len_to_column)\n",
    "\n",
    "        to_column_combinations = []\n",
    "        for element in to_column.tolist():\n",
    "            list_element = [element] * len_from_column\n",
    "            to_column_combinations = to_column_combinations + list_element\n",
    "\n",
    "        to_column_combinations = pd.Series(to_column_combinations)\n",
    "\n",
    "        return from_column_combinations, to_column_combinations\n",
    "\n",
    "    @staticmethod\n",
    "    def create_levenshtein_array(\n",
    "        from_column: pd.Series,\n",
    "        to_column: pd.Series,\n",
    "        len_from_column: int,\n",
    "        len_to_column: int,\n",
    "        maxlen_from_column: int,\n",
    "        maxlen_to_column: int,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Creates a levenshtein matrix for alle from-to-string-combinations at the\n",
    "        same time in a vectorized fashion\n",
    "\n",
    "        Args:\n",
    "            from_column (pandas.Series): combinations of the from_column (needs\n",
    "                to be read together with the to_column)\n",
    "            to_column (pandas.Series): combinations of the to_column (needs to\n",
    "                be read together with the from_column)\n",
    "            len_from_column (int): number of elements in the from_column\n",
    "            len_to_column (int): number of elements in the to_column\n",
    "            maxlen_from_column (int): number of characters in the longest str\n",
    "                of the from_column\n",
    "            maxlen_to_column (int): number of characters in the longest str\n",
    "                of the to_column\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 3-dimensional array that includes the 2-dimensionl\n",
    "            levenshtein array for alle from-to-string-combinations\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        levenshtein_array = np.zeros(\n",
    "            [len_from_column * len_to_column, maxlen_from_column, maxlen_to_column],\n",
    "            \"int16\",\n",
    "        )\n",
    "\n",
    "        for from_column_index in range(maxlen_from_column):\n",
    "            for to_column_index in range(maxlen_to_column):\n",
    "\n",
    "                if from_column_index == 0:\n",
    "\n",
    "                    insertion = np.array(\n",
    "                        [np.iinfo(\"int16\").max] * len_from_column * len_to_column\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    insertion = levenshtein_array[\n",
    "                        :, from_column_index - 1, to_column_index\n",
    "                    ] + (~pd.isnull(from_column.str[from_column_index])).astype(\"int16\")\n",
    "\n",
    "                if to_column_index == 0:\n",
    "\n",
    "                    deletion = np.array(\n",
    "                        [np.iinfo(\"int16\").max] * len_from_column * len_to_column\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    deletion = levenshtein_array[\n",
    "                        :, from_column_index, to_column_index - 1\n",
    "                    ] + (~pd.isnull(to_column.str[to_column_index])).astype(\"int16\")\n",
    "\n",
    "                if from_column_index == 0 or to_column_index == 0:\n",
    "\n",
    "                    replacement = np.array(\n",
    "                        [np.iinfo(\"int16\").max] * len_from_column * len_to_column\n",
    "                    )\n",
    "\n",
    "                    if from_column_index == 0 and to_column_index == 0:\n",
    "\n",
    "                        comparison = (\n",
    "                            from_column.str[from_column_index]\n",
    "                            != to_column.str[to_column_index]\n",
    "                        )\n",
    "                        replacement = comparison.astype(\"int16\")\n",
    "\n",
    "                else:\n",
    "\n",
    "                    comparison = (\n",
    "                        from_column.str[from_column_index]\n",
    "                        != to_column.str[to_column_index]\n",
    "                    )\n",
    "                    replacement = levenshtein_array[\n",
    "                        :, from_column_index - 1, to_column_index - 1\n",
    "                    ] + comparison.astype(\"int16\")\n",
    "\n",
    "                levenshtein_array[:, from_column_index, to_column_index] = np.array(\n",
    "                    [insertion, deletion, replacement]\n",
    "                ).min(axis=0)\n",
    "\n",
    "        return levenshtein_array\n",
    "\n",
    "    @staticmethod\n",
    "    def create_maxlen_matrix(\n",
    "        from_column: pd.Series, to_column: pd.Series\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a matrix which contains the maximum of the string lengths of all\n",
    "        from-to-combination pairs\n",
    "\n",
    "        Args:\n",
    "            from_column (pandas.Series): from_column strings\n",
    "            to_column (pandas.Series): to_column strings\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: matrix which contains the maximum length of the\n",
    "                pairs\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        from_column_len = from_column.shape[0]\n",
    "        to_column_len = to_column.shape[0]\n",
    "\n",
    "        divisor_frame_from = pd.concat(\n",
    "            [from_column.str.len()] * to_column_len, axis=1\n",
    "        ).T\n",
    "\n",
    "        # get rid of row and column index\n",
    "        divisor_frame_from = divisor_frame_from.T.reset_index(drop=True).T\n",
    "        divisor_frame_from.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        divisor_frame_to = pd.concat([to_column.str.len()] * from_column_len, axis=1)\n",
    "\n",
    "        # get rid of row and column index\n",
    "        divisor_frame_to = divisor_frame_to.T.reset_index(drop=True).T\n",
    "        divisor_frame_to.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        maxlen_matrix = (\n",
    "            pd.concat([divisor_frame_from, divisor_frame_to])\n",
    "            .groupby(level=0)\n",
    "            .max()\n",
    "            .astype(\"float32\")\n",
    "        )\n",
    "\n",
    "        return maxlen_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
